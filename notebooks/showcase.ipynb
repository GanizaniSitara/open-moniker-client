{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Moniker System Showcase\n\nThis notebook demonstrates the **Moniker** unified data access system:\n\n- **5 source types**: Snowflake, Oracle, REST, Excel, MS-SQL — all accessed through the same API\n- **Reflection API** (`CatalogReflector`): discover, search, and inspect catalog metadata without fetching data\n- **Rich metadata**: data quality scores, schema introspection, freshness, SLAs, and documentation links\n- **Pre-flight checks**: use metadata to understand data characteristics (like timeseries gaps) before querying\n- **Request & approval workflow**: submit moniker requests, review, approve/reject via REST API\n\n### Prerequisites\n\n1. Install the client library:\n```bash\npip install -e ~/open-moniker-client\n```\n\n2. Start the Moniker service:\n```bash\ncd ~/open-moniker-client && python bring_up.py --server\n```"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import sys, os\n\n# moniker_client is pip-installed (pip install -e ~/open-moniker-client)\n# We only need path setup for the mock data adapters used in demo mode\nfor p in [\n    os.path.expanduser(\"~/open-moniker-svc/src\"),\n    os.path.expanduser(\"~/open-moniker-svc/external/moniker-data/src\"),\n]:\n    if p not in sys.path:\n        sys.path.insert(0, p)\n\nfrom moniker_client import (\n    Moniker, MonikerClient, ClientConfig,\n    CatalogReflector,\n    SearchResult, CatalogStats, SchemaInfo,\n)\n\n# Ensure all 5 mock adapters are initialized so client-side reads work\nfrom moniker_data.adapters.oracle import MockOracleAdapter\nfrom moniker_data.adapters.snowflake import MockSnowflakeAdapter\nfrom moniker_data.adapters.rest import MockRestAdapter\nfrom moniker_data.adapters.excel import MockExcelAdapter\nfrom moniker_data.adapters.mssql import MockMssqlAdapter\n\nMockOracleAdapter()\nMockSnowflakeAdapter()\nMockRestAdapter()\nMockExcelAdapter()\nMockMssqlAdapter()\n\n# Create client pointing to the running service\nclient = MonikerClient(config=ClientConfig(service_url=\"http://localhost:8050\"))\n\nprint(\"Client ready:\", client.config.service_url)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section B: Catalog Discovery with CatalogReflector\n",
    "\n",
    "The `CatalogReflector` provides a high-level facade for exploring the catalog — no data fetching required.\n",
    "All 9 reflector methods are exercised in this section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total monikers: 27\n",
      "\n",
      "By status:\n",
      "  active               27\n",
      "\n",
      "By source type:\n",
      "  snowflake            3\n",
      "  rest                 4\n",
      "  oracle               1\n",
      "  static               1\n",
      "  opensearch           1\n",
      "  excel                1\n",
      "  mssql                2\n",
      "\n",
      "Ownership coverage: 37%  (10 monikers with ownership)\n"
     ]
    }
   ],
   "source": [
    "# B1: Catalog Statistics — stats()\n",
    "reflector = CatalogReflector(client=client)\n",
    "\n",
    "stats = reflector.stats()\n",
    "\n",
    "print(f\"Total monikers: {stats.total_monikers}\")\n",
    "print(f\"\\nBy status:\")\n",
    "for status, count in stats.by_status.items():\n",
    "    print(f\"  {status:20s} {count}\")\n",
    "print(f\"\\nBy source type:\")\n",
    "for src, count in stats.by_source_type.items():\n",
    "    print(f\"  {src:20s} {count}\")\n",
    "coverage = stats.ownership_coverage\n",
    "if isinstance(coverage, dict):\n",
    "    print(f\"\\nOwnership coverage: {coverage.get('coverage_percent', 0):.0f}%  ({coverage.get('has_ownership', 0)} monikers with ownership)\")\n",
    "else:\n",
    "    print(f\"\\nOwnership coverage: {coverage:.0%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# B2: Top-level Domains — /domains governance metadata\n",
    "import httpx\n",
    "\n",
    "with httpx.Client(timeout=30) as http:\n",
    "    resp = http.get(f\"{client.config.service_url}/domains\")\n",
    "    resp.raise_for_status()\n",
    "    domains_data = resp.json()\n",
    "\n",
    "domains = domains_data.get(\"domains\", [])\n",
    "\n",
    "print(f\"{'Domain':<16} {'Owner':<34} {'Category':<12} {'Confidentiality':<18}\")\n",
    "print(\"-\" * 82)\n",
    "for d in domains:\n",
    "    print(f\"{d['name']:<16} {d.get('owner',''):<34} {d.get('data_category',''):<12} {d.get('confidentiality',''):<18}\")\n",
    "\n",
    "print(f\"\\nRegistered domains: {domains_data.get('count', len(domains))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-11T10:30:38.562911Z",
     "iopub.status.busy": "2026-02-11T10:30:38.562724Z",
     "iopub.status.idle": "2026-02-11T10:30:38.578205Z",
     "shell.execute_reply": "2026-02-11T10:30:38.577149Z"
    }
   },
   "outputs": [],
   "source": [
    "# B3: Source Type Distribution — sources()\n",
    "sources = reflector.sources()\n",
    "\n",
    "print(\"Source type distribution:\")\n",
    "for src_type, count in sorted(sources.items(), key=lambda x: -x[1]):\n",
    "    bar = '#' * count\n",
    "    print(f\"  {src_type:<15} {count:>3}  {bar}\")\n",
    "\n",
    "assert \"mssql\" in sources, \"MS-SQL source type should be present!\"\n",
    "print(f\"\\nMS-SQL monikers in catalog: {sources['mssql']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-11T10:30:38.579818Z",
     "iopub.status.busy": "2026-02-11T10:30:38.579589Z",
     "iopub.status.idle": "2026-02-11T10:30:38.605511Z",
     "shell.execute_reply": "2026-02-11T10:30:38.604632Z"
    }
   },
   "outputs": [],
   "source": [
    "# B4: Search — search(query) and search(\"\", source_type=)\n",
    "\n",
    "# Find credit-related monikers\n",
    "credit_results = reflector.search(\"credit\")\n",
    "print(f\"Search 'credit': {credit_results.total_results} results\")\n",
    "for r in credit_results.results:\n",
    "    has_src = r.get('has_source_binding', False)\n",
    "    print(f\"  {r['path']:<30} has_source={has_src!s:<6} tags={r.get('tags', [])}\")\n",
    "\n",
    "# Find all MS-SQL backed monikers using source_type filter\n",
    "# (post-filters on source_type field when available in results)\n",
    "print()\n",
    "mssql_results = reflector.search(\"mssql\")\n",
    "print(f\"Search 'mssql': {mssql_results.total_results} results\")\n",
    "for r in mssql_results.results:\n",
    "    print(f\"  {r['path']:<30} {r.get('display_name', '')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-11T10:30:38.607039Z",
     "iopub.status.busy": "2026-02-11T10:30:38.606897Z",
     "iopub.status.idle": "2026-02-11T10:30:38.642742Z",
     "shell.execute_reply": "2026-02-11T10:30:38.641760Z"
    }
   },
   "outputs": [],
   "source": [
    "# B5: Filter by Status and Tags — by_status(), deprecated(), by_tag()\n",
    "\n",
    "# All active monikers\n",
    "active_results = client.search(\"a\", status=\"active\", limit=200)\n",
    "print(f\"Active monikers (via search): {active_results.total_results}\")\n",
    "for a in active_results.results[:5]:\n",
    "    print(f\"  {a['path']}\")\n",
    "if active_results.total_results > 5:\n",
    "    print(f\"  ... and {active_results.total_results - 5} more\")\n",
    "\n",
    "# Deprecated monikers\n",
    "print()\n",
    "try:\n",
    "    dep_results = client.search(\"deprecated\", status=\"deprecated\", limit=200)\n",
    "    print(f\"Deprecated monikers: {dep_results.total_results}\")\n",
    "    for d in dep_results.results:\n",
    "        print(f\"  {d['path']}: {d.get('deprecation_message', 'no message')}\")\n",
    "except Exception:\n",
    "    print(\"Deprecated monikers: 0  (none in demo catalog)\")\n",
    "\n",
    "# Tag-based discovery — search for \"credit\" and filter by tag\n",
    "print()\n",
    "tag_results = client.search(\"credit\", limit=200)\n",
    "credit_tagged = [r for r in tag_results.results if \"credit\" in r.get(\"tags\", [])]\n",
    "print(f\"Monikers tagged 'credit': {len(credit_tagged)}\")\n",
    "for t in credit_tagged:\n",
    "    print(f\"  {t['path']:<30} tags={t.get('tags', [])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section C: Schema Introspection & Pre-Flight Checks\n",
    "\n",
    "Before fetching data, inspect metadata to understand what we're getting and check for known issues.\n",
    "This pattern — **\"check metadata first, then fetch\"** — is critical for production workflows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-11T10:30:38.644416Z",
     "iopub.status.busy": "2026-02-11T10:30:38.644268Z",
     "iopub.status.idle": "2026-02-11T10:30:38.681863Z",
     "shell.execute_reply": "2026-02-11T10:30:38.680614Z"
    }
   },
   "outputs": [],
   "source": [
    "# C1: Schema introspection — schema()\n",
    "schema = reflector.schema(\"credit.exposures\")\n",
    "\n",
    "print(f\"Moniker:       {schema.moniker}\")\n",
    "print(f\"Granularity:   {schema.granularity}\")\n",
    "print(f\"Primary key:   {schema.primary_key}\")\n",
    "print(f\"Semantic tags: {schema.semantic_tags}\")\n",
    "\n",
    "# Get related_monikers from metadata directly (richer than schema view)\n",
    "meta_rel = client.metadata(\"credit.exposures\")\n",
    "related = (meta_rel.relationships or {}).get(\"related_monikers\", [])\n",
    "print(f\"Related:       {related}\")\n",
    "\n",
    "print(f\"\\nColumns ({len(schema.columns)}):\")\n",
    "print(f\"  {'Name':<22} {'Type':<10} {'Semantic':<12} {'Description'}\")\n",
    "print(\"  \" + \"-\" * 80)\n",
    "for col in schema.columns:\n",
    "    print(f\"  {col['name']:<22} {col.get('type',''):<10} {(col.get('semantic_type') or ''):<12} {col.get('description', '')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-11T10:30:38.683483Z",
     "iopub.status.busy": "2026-02-11T10:30:38.683252Z",
     "iopub.status.idle": "2026-02-11T10:30:38.701839Z",
     "shell.execute_reply": "2026-02-11T10:30:38.699655Z"
    }
   },
   "outputs": [],
   "source": [
    "# C2: Metadata deep-dive via Moniker object\n",
    "m = Moniker(\"credit.exposures\", client=client)\n",
    "meta = m.metadata()\n",
    "\n",
    "print(\"=== Data Quality ===\")\n",
    "if meta.data_quality:\n",
    "    print(f\"  Quality score: {meta.data_quality.get('quality_score')}\")\n",
    "    print(f\"  Known issues:\")\n",
    "    for issue in meta.data_quality.get('known_issues', []):\n",
    "        print(f\"    - {issue}\")\n",
    "\n",
    "print(\"\\n=== Temporal Coverage ===\")\n",
    "if meta.temporal_coverage:\n",
    "    for k, v in meta.temporal_coverage.items():\n",
    "        print(f\"  {k}: {v}\")\n",
    "\n",
    "print(\"\\n=== Cost Indicators ===\")\n",
    "if meta.cost_indicators:\n",
    "    for k, v in meta.cost_indicators.items():\n",
    "        print(f\"  {k}: {v}\")\n",
    "\n",
    "print(\"\\n=== Documentation ===\")\n",
    "if meta.documentation:\n",
    "    for k, v in meta.documentation.items():\n",
    "        print(f\"  {k}: {v}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-11T10:30:38.703895Z",
     "iopub.status.busy": "2026-02-11T10:30:38.703728Z",
     "iopub.status.idle": "2026-02-11T10:30:38.737641Z",
     "shell.execute_reply": "2026-02-11T10:30:38.737212Z"
    }
   },
   "outputs": [],
   "source": [
    "# C3: Data Quality Gate — check metadata BEFORE fetching\n",
    "#\n",
    "# Pattern: metadata told us to expect gaps, let's verify in the data.\n",
    "\n",
    "expect_gaps = False\n",
    "if meta.data_quality:\n",
    "    for issue in meta.data_quality.get(\"known_issues\", []):\n",
    "        if \"gap\" in issue.lower():\n",
    "            print(f\"WARNING (from metadata): {issue}\")\n",
    "            expect_gaps = True\n",
    "\n",
    "# Now fetch and verify\n",
    "result = client.fetch(\"credit.exposures\", limit=10000)\n",
    "print(f\"\\nFetched {result.row_count} rows, {len(result.columns)} columns\")\n",
    "\n",
    "# Detect actual gaps in ASOF_DATE\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "dates = sorted(set(row[\"ASOF_DATE\"] for row in result.data))\n",
    "gaps = []\n",
    "for i in range(1, len(dates)):\n",
    "    d1 = datetime.strptime(dates[i-1], \"%Y-%m-%d\").date()\n",
    "    d2 = datetime.strptime(dates[i], \"%Y-%m-%d\").date()\n",
    "    delta = (d2 - d1).days\n",
    "    if delta > 1:\n",
    "        gaps.append((dates[i-1], dates[i], delta))\n",
    "\n",
    "print(f\"\\nDate range: {dates[0]} to {dates[-1]} ({len(dates)} unique dates)\")\n",
    "print(f\"Gaps found: {len(gaps)}\")\n",
    "for g in gaps[:5]:\n",
    "    print(f\"  {g[0]} -> {g[1]} ({g[2]} days)\")\n",
    "if len(gaps) > 5:\n",
    "    print(f\"  ... and {len(gaps) - 5} more\")\n",
    "\n",
    "if expect_gaps and len(gaps) > 0:\n",
    "    print(\"\\nMetadata correctly warned about timeseries gaps (weekends).\")\n",
    "elif not expect_gaps and len(gaps) == 0:\n",
    "    print(\"\\nNo gaps expected, none found.\")\n",
    "else:\n",
    "    print(\"\\nUnexpected result — investigate further.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section D: Multi-Source Data Access\n",
    "\n",
    "The same client API works across **5 different backends**: Snowflake, Oracle, REST, Excel, MS-SQL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-11T10:30:38.740299Z",
     "iopub.status.busy": "2026-02-11T10:30:38.739755Z",
     "iopub.status.idle": "2026-02-11T10:30:38.764375Z",
     "shell.execute_reply": "2026-02-11T10:30:38.763508Z"
    }
   },
   "outputs": [],
   "source": [
    "# D1: MS-SQL — Credit Exposures via server-side fetch\n",
    "m = Moniker(\"credit.exposures\", client=client)\n",
    "result = m.fetch(limit=5000)\n",
    "data = result.data\n",
    "\n",
    "print(f\"Moniker.fetch() returned {len(data)} rows\")\n",
    "print(f\"\\nFirst 10 rows (selected columns):\")\n",
    "print(f\"{'ASOF_DATE':<12} {'CP_ID':<8} {'TYPE':<14} {'NOTIONAL':>16} {'CVA':>12} {'RATING':<6}\")\n",
    "print(\"-\" * 72)\n",
    "for row in data[:10]:\n",
    "    print(f\"{row['ASOF_DATE']:<12} {row['COUNTERPARTY_ID']:<8} {row['EXPOSURE_TYPE']:<14} \"\n",
    "          f\"{row['NOTIONAL']:>16,.2f} {row['CVA']:>12,.2f} {row['RATING']:<6}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-11T10:30:38.766136Z",
     "iopub.status.busy": "2026-02-11T10:30:38.765961Z",
     "iopub.status.idle": "2026-02-11T10:30:38.783172Z",
     "shell.execute_reply": "2026-02-11T10:30:38.782788Z"
    }
   },
   "outputs": [],
   "source": [
    "# D2: Server-side fetch with execution stats\n",
    "result = client.fetch(\"credit.exposures\", limit=10)\n",
    "\n",
    "print(f\"Path:            {result.path}\")\n",
    "print(f\"Source type:     {result.source_type}\")\n",
    "print(f\"Columns:         {result.columns}\")\n",
    "print(f\"Row count:       {result.row_count}\")\n",
    "print(f\"Execution time:  {result.execution_time_ms:.1f} ms\")\n",
    "print(f\"Query executed:  {result.query_executed[:80]}...\" if result.query_executed and len(result.query_executed) > 80 else f\"Query executed:  {result.query_executed}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-11T10:30:38.785341Z",
     "iopub.status.busy": "2026-02-11T10:30:38.785145Z",
     "iopub.status.idle": "2026-02-11T10:30:38.800759Z",
     "shell.execute_reply": "2026-02-11T10:30:38.800200Z"
    }
   },
   "outputs": [],
   "source": [
    "# D3: REST source — Commodities (demo of multi-source catalog)\n",
    "# The REST adapter simulates a NEFA commodities API.\n",
    "# Here we resolve to show the REST binding, and use the adapter directly.\n",
    "\n",
    "resolved = client.resolve(\"commodities.derivatives/energy/ALL\")\n",
    "print(f\"Source type: {resolved.source_type}\")\n",
    "print(f\"Connection:  {resolved.connection.get('base_url', 'n/a')}\")\n",
    "print(f\"Query:       {resolved.query}\")\n",
    "\n",
    "# Call REST adapter directly to show energy data\n",
    "from moniker_data.adapters.rest import MockRestAdapter\n",
    "rest = MockRestAdapter()\n",
    "energy_data = rest.get_energy(\"CL\", \"SPOT\")\n",
    "print(f\"\\nDirect adapter call — CL SPOT prices: {len(energy_data)} rows\")\n",
    "for row in energy_data[:5]:\n",
    "    print(f\"  {row['TIMESTAMP']:<22} {row['SYMBOL']:<5} {row['CONTRACT']:<6} ${row['PRICE']:>8.2f}  {row['NAME']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-11T10:30:38.803411Z",
     "iopub.status.busy": "2026-02-11T10:30:38.802781Z",
     "iopub.status.idle": "2026-02-11T10:30:38.842988Z",
     "shell.execute_reply": "2026-02-11T10:30:38.842516Z"
    }
   },
   "outputs": [],
   "source": [
    "# D4: Compare schemas — credit.exposures vs credit.limits\n",
    "schema_exp = reflector.schema(\"credit.exposures\")\n",
    "schema_lim = reflector.schema(\"credit.limits\")\n",
    "\n",
    "print(f\"{'':30} {'credit.exposures':>20} {'credit.limits':>20}\")\n",
    "print(\"-\" * 72)\n",
    "print(f\"{'Columns':30} {len(schema_exp.columns):>20} {len(schema_lim.columns):>20}\")\n",
    "print(f\"{'Primary key':30} {str(schema_exp.primary_key):>20} {str(schema_lim.primary_key):>20}\")\n",
    "print(f\"{'Granularity':30} {(schema_exp.granularity or '')[:20]:>20} {(schema_lim.granularity or '')[:20]:>20}\")\n",
    "\n",
    "# Get related_monikers from metadata for each\n",
    "meta_exp = client.metadata(\"credit.exposures\")\n",
    "meta_lim = client.metadata(\"credit.limits\")\n",
    "rel_exp = (meta_exp.relationships or {}).get(\"related_monikers\", [])\n",
    "rel_lim = (meta_lim.relationships or {}).get(\"related_monikers\", [])\n",
    "print(f\"{'Related monikers':30} {str(rel_exp):>20} {str(rel_lim):>20}\")\n",
    "\n",
    "# Show the join key\n",
    "exp_cols = {c['name'] for c in schema_exp.columns}\n",
    "lim_cols = {c['name'] for c in schema_lim.columns}\n",
    "shared = exp_cols & lim_cols\n",
    "print(f\"\\nShared columns (join keys): {shared}\")\n",
    "print(f\"These two datasets are linked via related_monikers and share COUNTERPARTY_ID for joins.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section E: Resolution, Lineage & Ownership\n",
    "\n",
    "Every moniker can be **resolved** to its underlying source connection details,\n",
    "and **described** with full ownership lineage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-11T10:30:38.845413Z",
     "iopub.status.busy": "2026-02-11T10:30:38.845262Z",
     "iopub.status.idle": "2026-02-11T10:30:38.859447Z",
     "shell.execute_reply": "2026-02-11T10:30:38.858560Z"
    }
   },
   "outputs": [],
   "source": [
    "# E1: Resolve — see the underlying connection details\n",
    "resolved = client.resolve(\"credit.exposures\")\n",
    "\n",
    "print(f\"Moniker:     {resolved.moniker}\")\n",
    "print(f\"Source type: {resolved.source_type}\")\n",
    "print(f\"Connection:\")\n",
    "for k, v in resolved.connection.items():\n",
    "    if k != 'query':\n",
    "        print(f\"  {k}: {v}\")\n",
    "print(f\"Query:       {resolved.query[:100]}...\" if resolved.query and len(resolved.query) > 100 else f\"Query:       {resolved.query}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-11T10:30:38.860954Z",
     "iopub.status.busy": "2026-02-11T10:30:38.860815Z",
     "iopub.status.idle": "2026-02-11T10:30:38.896713Z",
     "shell.execute_reply": "2026-02-11T10:30:38.895679Z"
    }
   },
   "outputs": [],
   "source": [
    "# E2: Describe (domain + leaf) and Lineage\n",
    "\n",
    "# Domain-level ownership\n",
    "desc_domain = client.describe(\"credit\")\n",
    "print(\"=== Domain: credit ===\")\n",
    "print(f\"  Display name: {desc_domain.get('display_name')}\")\n",
    "print(f\"  Description:  {desc_domain.get('description', '')[:80]}\")\n",
    "print(f\"  Owner:        {desc_domain.get('ownership', {}).get('accountable_owner')}\")\n",
    "print(f\"  Support:      {desc_domain.get('ownership', {}).get('support_channel')}\")\n",
    "\n",
    "# Leaf-level ownership\n",
    "print()\n",
    "desc_leaf = client.describe(\"credit.exposures\")\n",
    "print(\"=== Leaf: credit.exposures ===\")\n",
    "print(f\"  Display name:  {desc_leaf.get('display_name')}\")\n",
    "print(f\"  Source type:   {desc_leaf.get('source_type')}\")\n",
    "print(f\"  Tags:          {desc_leaf.get('tags')}\")\n",
    "print(f\"  Data quality:  {desc_leaf.get('data_quality', {}).get('quality_score')}\")\n",
    "\n",
    "# Lineage — shows ownership provenance (where each field was defined)\n",
    "print()\n",
    "lineage = client.lineage(\"credit.exposures\")\n",
    "print(\"=== Lineage ===\")\n",
    "print(f\"  Path:    {lineage.get('path')}\")\n",
    "print(f\"  Source:  {lineage.get('source', {}).get('type')} (bound at {lineage.get('source', {}).get('binding_defined_at')})\")\n",
    "own = lineage.get(\"ownership\", {})\n",
    "print(f\"  Owner:   {own.get('accountable_owner')} (defined at {own.get('accountable_owner_defined_at')})\")\n",
    "print(f\"  Support: {own.get('support_channel')} (defined at {own.get('support_channel_defined_at')})\")\n",
    "print(f\"  Hierarchy: {' -> '.join(lineage.get('path_hierarchy', []))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "---\n## Summary\n\nThis notebook exercised the full Moniker system:\n\n| Feature | Demonstrated |\n|---|---|\n| `CatalogReflector.stats()` | Catalog-wide statistics |\n| `CatalogReflector.domains()` | Top-level domain listing |\n| `CatalogReflector.sources()` | Source type distribution |\n| `CatalogReflector.search(query)` | Text search |\n| `CatalogReflector.search(\"\", source_type=)` | Source type filter |\n| `CatalogReflector.by_status(status)` | Status filter |\n| `CatalogReflector.deprecated()` | Find deprecated monikers |\n| `CatalogReflector.by_tag(tag)` | Tag-based discovery |\n| `CatalogReflector.schema(moniker)` | Schema introspection |\n| `Moniker.metadata()` | Rich AI-discoverable metadata |\n| `Moniker.read()` | Client-side data read |\n| `MonikerClient.fetch()` | Server-side query execution |\n| `MonikerClient.resolve()` | Source resolution |\n| `MonikerClient.describe()` | Ownership & governance |\n| `MonikerClient.lineage()` | Ownership lineage chain |\n| Data quality gate | Check metadata for gaps before fetching |\n| Multi-source access | MS-SQL, REST, schema comparison |\n| **POST /requests** | Submit moniker request |\n| **POST /requests/{id}/comment** | Governance review thread |\n| **POST /requests/{id}/approve** | Approve → catalog ACTIVE |\n| **POST /requests/{id}/reject** | Reject with compliance reason |\n| **GET /requests** | Review queue summary |\n\nAll **9 CatalogReflector methods** exercised. All **5 source types** represented. Full **request & approval workflow** demonstrated."
  },
  {
   "cell_type": "markdown",
   "source": "---\n## Section F: Request & Approval Workflow\n\nThe Moniker system includes a **governance workflow** for requesting new monikers. This is a REST API — no special client needed.\n\n**Workflow**: Submit request → Review queue → Approve or Reject → Moniker goes ACTIVE (or back to DRAFT)\n\nThe review queue is also available as a web UI at `/requests/ui` and developer docs at `/requests/api-guide`.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# F1: Review Queue Overview — see what's pending\nimport httpx\n\nBASE = client.config.service_url\n\nwith httpx.Client(timeout=30) as http:\n    resp = http.get(f\"{BASE}/requests\")\n    queue = resp.json()\n\nprint(f\"Review Queue Summary\")\nprint(f\"{'='*40}\")\nfor status, count in queue[\"by_status\"].items():\n    print(f\"  {status:<20} {count}\")\n\nprint(f\"\\nAll requests:\")\nprint(f\"  {'ID':<10} {'Status':<18} {'Path':<40} {'Requester'}\")\nprint(f\"  {'-'*90}\")\nfor r in queue[\"requests\"]:\n    name = r.get(\"requester\", {}).get(\"name\", \"?\")\n    print(f\"  {r['request_id']:<10} {r['status']:<18} {r['path']:<40} {name}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# F2: Submit a new moniker request\n#\n# A developer wants a new moniker for credit loss forecasting data.\n# This goes into the review queue for governance approval.\n\nwith httpx.Client(timeout=30) as http:\n    resp = http.post(f\"{BASE}/requests\", json={\n        \"path\": \"credit/loss_forecast/ifrs9\",\n        \"display_name\": \"IFRS 9 Credit Loss Forecasts\",\n        \"description\": \"Expected credit loss forecasts by portfolio segment under IFRS 9\",\n        \"justification\": \"Risk team needs ECL forecasts for quarterly provisioning under IFRS 9\",\n        \"requester\": {\n            \"name\": \"Demo Analyst\",\n            \"email\": \"demo.analyst@firm.com\",\n            \"team\": \"Credit Risk\",\n            \"app_id\": \"risk-dashboard\",\n        },\n        \"adop\": \"risk-head@firm.com\",\n        \"adop_name\": \"Risk Head\",\n        \"ads\": \"credit-risk-governance@firm.com\",\n        \"ads_name\": \"Credit Risk Governance\",\n        \"source_binding_type\": \"snowflake\",\n        \"source_binding_config\": {\n            \"account\": \"firm.us-east-1\",\n            \"warehouse\": \"RISK_WH\",\n            \"database\": \"CREDIT_MODELS\",\n            \"schema\": \"ECL\",\n        },\n        \"tags\": [\"credit-risk\", \"IFRS9\", \"ECL\", \"forecasting\"],\n    })\n\nif resp.status_code == 409:\n    print(f\"Request already exists (idempotent) — skipping to find it\")\n    all_reqs = http.get(f\"{BASE}/requests\").json()\n    req = next((r for r in all_reqs[\"requests\"] if r[\"path\"] == \"credit/loss_forecast/ifrs9\"), None)\n    request_id = req[\"request_id\"] if req else None\n    print(f\"  Found: {request_id}\")\nelse:\n    resp.raise_for_status()\n    result = resp.json()\n    request_id = result[\"request_id\"]\n    print(f\"Submitted! Request ID: {request_id}\")\n    print(f\"  Status:  {result['status']}\")\n    print(f\"  Message: {result['message']}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# F3: Add a review comment (governance discussion)\n\nif request_id:\n    with httpx.Client(timeout=30) as http:\n        resp = http.post(f\"{BASE}/requests/{request_id}/comment\", json={\n            \"author\": \"data-governance@firm.com\",\n            \"author_name\": \"Data Governance\",\n            \"content\": \"Confirmed: Snowflake schema CREDIT_MODELS.ECL is provisioned. ADOP and ADS look correct.\",\n        })\n        updated = resp.json()\n\n    print(f\"Comment added to {request_id}\")\n    print(f\"\\nReview thread ({len(updated['comments'])} comments):\")\n    for c in updated[\"comments\"]:\n        action = f\" [{c['action'].upper()}]\" if c.get(\"action\") != \"comment\" else \"\"\n        print(f\"  {c.get('author_name', c['author'])}{action}: {c['content'][:80]}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# F4: Approve the request — moniker goes ACTIVE in the catalog\n\nif request_id:\n    with httpx.Client(timeout=30) as http:\n        resp = http.post(f\"{BASE}/requests/{request_id}/approve\", json={\n            \"actor\": \"risk-head@firm.com\",\n            \"actor_name\": \"Risk Head\",\n            \"reason\": \"Approved — IFRS 9 ECL forecasts are a regulatory requirement. Schema validated.\",\n        })\n\n        if resp.status_code == 400:\n            print(f\"Already processed: {resp.json().get('detail')}\")\n        else:\n            resp.raise_for_status()\n            approved = resp.json()\n            print(f\"Request {approved['request_id']} APPROVED\")\n            print(f\"  Path:        {approved['path']}\")\n            print(f\"  Status:      {approved['status']}\")\n            print(f\"  Reviewed by: {approved['reviewed_by']}\")\n            print(f\"  Reviewed at: {approved['reviewed_at']}\")\n\n    # Verify the moniker is now visible in the catalog\n    print(f\"\\nCatalog verification:\")\n    try:\n        desc = client.describe(\"credit/loss_forecast/ifrs9\")\n        print(f\"  Path found:    {desc.get('path')}\")\n        print(f\"  Status:        {desc.get('status')}\")\n        print(f\"  Display name:  {desc.get('display_name')}\")\n        print(f\"  Tags:          {desc.get('tags')}\")\n    except Exception as e:\n        print(f\"  (Node registered but describe may not be available: {type(e).__name__})\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# F5: Rejection flow — submit and reject a bad request\n\nwith httpx.Client(timeout=30) as http:\n    # Submit a request that should be rejected (PII in a shared namespace)\n    resp = http.post(f\"{BASE}/requests\", json={\n        \"path\": \"credit/pii_enriched\",\n        \"display_name\": \"Credit Data with Client PII\",\n        \"description\": \"Credit exposures enriched with client personal information\",\n        \"justification\": \"Want combined view for client reporting\",\n        \"requester\": {\n            \"name\": \"Demo Analyst\",\n            \"email\": \"demo.analyst@firm.com\",\n            \"team\": \"Client Reporting\",\n        },\n        \"tags\": [\"PII\", \"credit-risk\"],\n    })\n\n    if resp.status_code == 409:\n        print(\"Request already exists — finding it\")\n        all_reqs = http.get(f\"{BASE}/requests\").json()\n        bad_req = next((r for r in all_reqs[\"requests\"] if r[\"path\"] == \"credit/pii_enriched\"), None)\n        bad_id = bad_req[\"request_id\"] if bad_req else None\n    else:\n        resp.raise_for_status()\n        bad_id = resp.json()[\"request_id\"]\n        print(f\"Submitted: {bad_id}\")\n\n    if bad_id:\n        # Reject it\n        resp = http.post(f\"{BASE}/requests/{bad_id}/reject\", json={\n            \"actor\": \"compliance@firm.com\",\n            \"actor_name\": \"Compliance\",\n            \"reason\": \"PII cannot be co-located with credit data in a shared namespace. Use a restricted PII moniker instead.\",\n        })\n\n        if resp.status_code == 400:\n            print(f\"Already processed: {resp.json().get('detail')}\")\n        else:\n            resp.raise_for_status()\n            rejected = resp.json()\n            print(f\"\\nRequest {rejected['request_id']} REJECTED\")\n            print(f\"  Reason: {rejected['rejection_reason']}\")\n\n# Final queue state\nwith httpx.Client(timeout=30) as http:\n    final = http.get(f\"{BASE}/requests\").json()\n\nprint(f\"\\nFinal queue state:\")\nfor status, count in final[\"by_status\"].items():\n    print(f\"  {status:<20} {count}\")\n\nprint(f\"\\nReview Queue UI:  {BASE}/requests/ui\")\nprint(f\"API Guide:        {BASE}/requests/api-guide\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}